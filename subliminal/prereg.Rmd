---
title           : "Robustness of the subliminal cue effect: A planned preregistered meta-analysis"
shorttitle      : "subliminal cues - rubust or not (interrobang)"
date            : "`r Sys.setlocale('LC_TIME', 'C'); format(Sys.time(), '%d\\\\. %B %Y')`"

author: 
  - name        : Stephen Bennett
    affiliation : 1
  - name        : Gabriel Estrella
    affiliation : 1
  - name        : Mac Strelioff
    affiliation : 1
  - name        : Joachim Vandekerckhove
    affiliation : 1
  - name        : Jeffrey Rouder
    affiliation : 1
  

affiliation:
  - id          : 1
    institution : University of California, Irvine
    
output: prereg::cos_prereg
---

# Study Information

## Title

`r rmarkdown::metadata$title`

## Research questions

We aim to test whether the subliminal cue effect is robust to typical variation in experimental methods that might occur from labratory to labratory. Such variation typifies the sorts of generalizing to the real world. In general, is it the case that subliminal effects can substantively influence behavior?

It may be the case that these effects are restricted to some subset of the space of possible experimental methods. For instance, it may require a particular mask and cue contrast, mask duration, interval duration, and/or mask symbols. We aim to test the finding from (Reuss et al. 2015) that such an effect exists by thoroughly running through the space of all possible experiments.

## Models


# Sampling Plan

Fifty undergraduate students participating for course credit. 

## Existing data

**Registration prior to creation of data**. As of the date of submission of this research plan for preregistration, the data have not yet been collected, created, or realized.

## Data collection procedures

Undergraduate students will be recruited by the University of Missouri SONA system from the PSYCH 1000 course. Participants will be screened for normal or corrected to normal vision and will be fluent speakers of English. participants will be tested in the Perception and Cognition lab or Memory and Cognitive Aging lab at the University of Missouri.

## Sample size
We plan on asking each of 50 participants to judge 60 words and 60 non-words.  The total number of judgments is therefore `r 50*2*60`.  

## Sample size rationale

We think `r 50*2*60` judgments is a lot.  It is 5 times the number of judgments collected by Gardiner and Java in their Experiment 2.

# Variables

Manipulated
 - Stimulus type: word/ non-word
 - Probe type: old/ new

Measured
 - Frequency of New, Old and Remember, Know responses
 - Reaction time


# Design Plan

2 $\times$ 2 within subjects

## Study type

**Experiment**. A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials.

## Blinding

This study is a massively repeated within-subjects design.  What does blinding even mean when participants are assigned to both conditions.

## Study design
<!-- Describe your study design. Examples include two-group, factorial, randomized block, and repeated measures. Is it a between (unpaired), within-subject (paired), or mixed design? Describe any counterbalancing required. Typical study designs for observation studies include cohort, cross sectional, and case-control studies. -->

Repeated measures

### Stimuli

Sixty high familiarity concrete nouns with 1 syllable and 4 letters were taken from the MRC psycholinguistics database (Coltheart, 1981). Sixty non-words with 4 letters and 2-4 phonemes were selected from the ARC non-word database (Rastle et al., 2002). For each participant 30 words and 30 non-words are chosen at random to form the study set. Words and non-words are randomly intermixed. All 60 words and 60 non-words are presented at test in a random order. The words and non-words used in this study are copied below at the end of this document. Items are presented at the center of the screen in the Lucida Console font with a height of 2$^{\circ}$ of visual angle at an approximate viewing distance of 50 cm.

During the recognition test participants are presented with a single item in the center of the screen and two buttons (either labeled OLD and NEW or R and K, see below) that they can click on to respond. The buttons are circular with a radius of 2$^{\circ}$ and are presented $5^{\circ}$ below and $5^{\circ}$ to the left and right of the center of the screen.

### Procedure

Participants study 60 items (30 words and 30 non-words) in a randomly determined order. Each item appears on screen for 2 seconds followed by a 0.5 second inter-stimulus-interval. Following the study phase participants are given a 'spot-the-difference' task to complete for 10 minutes before moving on to the recognition test. During the recognition test participants are presented with items one at a time that they must first characterize as OLD or NEW using the mouse to click on labeled buttons on screen. Following an OLD response participants then make an additional characterization by clicking on buttons labeled R (for 'remembered') or K (for 'known'). Prior to the recognition test participants are instructed on the use of the R/K classification in a similar manner to the instruction used in Gardiner and Java (1990). These instructions are copied below in the final section of this document.

## Randomization
<!-- If you are doing a randomized study, how will you randomize, and at what level? -->

Order of presentation of word/ non-words is randomized. Whether a given word/ non-word is old or new is also determined randomly per person.

# Analysis Plan
<!-- You may describe one or more confirmatory analysis in this section. Remember, all analyses specified in this section must be reported in the final article, and any additional analyses must be clearly labeled as exploratory or hypothesis generating in the final paper. A confirmatory analysis plan must state up front which variables are predictors (independent) and which are the outcomes (dependent), otherwise it is an exploratory analysis.

You may describe exploratory analyses in this section, but a clear confirmatory analysis is required. An exploratory test is any test where a prediction is not made up front, or there are multiple possible tests that you are going to use. A statistically significant finding in an exploratory test is a great way to form a new confirmatory hypothesis, which could be registered at a later time.

To help you keep track of multiple analyses, you may label each for your reference. -->

We intend to use the Bayes factor approach to assessing equalities and inequalities as described in Haaf & Rouder (in press) and Rouder & Haaf (submitted). 

The key specifications that are needed are the scale on effect sizes.  We think a guess for $\sigma^2$ is somewhere around .3, and if effects are .2, then effect sizes should be around .67.  This value will be used to set our scales along the arguments of Haaf and Rouder (in press).  

## Statistical models
Defined above.

## Transformations
<!-- If you plan on transforming, centering, recoding the data, or will require a coding scheme for categorical variables, please describe that process. -->

Defined above.

## Follow-up analyses
<!-- If not specified previously, will you be conducting any confirmatory analyses to follow up on effects in your statistical model, such as subgroup analyses, pairwise or complex contrasts, or follow-up tests from interactions. Refer to the *Hypotheses* section to relate each hypothesis to a statistical analysis. Remember that any analyses not specified in this research plan must be noted as exploratory. -->

We will fit an equal variance signal detection model to assess the applicability of a simple one-process model.

## Inference criteria
<!-- What criteria will you use to make inferences? Please describe the information you'll use (e.g. p-values, Bayes factors, specific model fit indices), as well as cut-off criterion, where appropriate. Will you be using one or two tailed tests for each of your analyses? If you are comparing multiple conditions or testing multiple hypotheses, will you account for this? -->

Such considerations only make sense in the Neyman-Fisher statistical framework.  We don't make decisions .  Instead, we state the strength of evidence, and no criteria are needed.  See @Rouder:etal:2016c.

## Data exclusion
<!-- How will you determine what data or samples, if any, to exclude from your analyses? How will outliers be handled? -->

If the session is terminated (either by the participant or for technical reasons) the whole data set will be excluded. We have no set lower bound of performance, but we reserve the right to do exclude low-performing participants on an exploratory basis.  We do so with regards to the overall accuracy and explicitly not the accuracy-by-condition data.

## Missing data
<!-- How will you deal with incomplete or missing data? -->

Any missing will be replaced by recruiting additional participants (up to a total of 50).




## Exploratory analyses (optional)
<!-- If you plan to explore your data set to look for unexpected differences or relationships, you may describe those tests here. An exploratory test is any test where a prediction is not made up front, or there are multiple possible tests that you are going to use. A statistically significant finding in an exploratory test is a great way to form a new confirmatory hypothesis, which could be registered at a later time. -->

We do not have a set analysis script for the exploratory EVSD analysis. The script will look something like the one below. The data used here is from the graph for experiment 2 from Gardiner and Java [-@Gardiner:Java:1990].

```{r eval = F}
dat2=matrix(ncol=2,byrow=T,c(
.28,.16,
.19,.30,
.03,.12,
.04,.11))

new=1-apply(dat2,1,sum)
dat=cbind(dat2,new)
colnames(dat)=c("Rem","Know","New")
rownames(dat)=c("oldW","oldNW","newW","newNW")


pred=function(par)
{
oldW=diff(pnorm(c(-Inf,par[3:4],Inf),par[1],1))
oldNW=diff(pnorm(c(-Inf,par[5:6],Inf),par[2],1))
newW=diff(pnorm(c(-Inf,par[3:4],Inf),0,1))
newNW=diff(pnorm(c(-Inf,par[5:6],Inf),0,1))
p=rbind(oldW,oldNW,newW,newNW)
p=p[,3:1]
colnames(p)=c("Rem","Know","New")
rownames(p)=c("oldW","oldNW","newW","newNW")
return(p)
}

error=function(par,dat){
	p=pred(par) 
	return(sum ((qnorm(p)-qnorm(dat))^2))
	}

par=c(1,1,1,1.5,1,1.5)

error(par,dat)
g=optim(par,error,dat=dat)
h=nlm(error,g$par,dat=dat)
g=optim(h$estimate,error,dat=dat)

print(pred(g$par))
```



## Analysis scripts (optional)
<!-- The purpose of a fully commented analysis script is to unambiguously provide the responses to all of the questions raised in the analysis section. This step is not common, but we encourage you to try creating an analysis script, refine it using a modeled dataset, and use it in place of your written analysis plan.

Upload an analysis script with clear comments. This optional step is helpful in order to create a process that is completely transparent and increase the likelihood that your analysis can be replicated. We recommend that you run the code on a simulated dataset in order to check that it will run without errors. -->

Let `dat` be a $3\times IJ$ matrix of response frequencies for remember, know and new responses per condition and person. Let `cond` be a vector of length $IJ$ denoting the condition $j$ for each column in `dat`. Likewise, let `sub` be a vector of length $IJ$ denoting the participant $i$ for each column in `dat`.

```{r, eval = F}
library("knitr")
library('BayesFactor')

make_y <- function(dat){ 
  #vector of 3 values
  #, first = number of remember responses
  #, second = number of know responses
  #, third = number of new responses
  if(!is.vector(dat)){return("data not in the right format")}
  if(length(dat)!=3){
    return("please submit vector with #remember
           , #know and #new responses")}
  
  p_r <- (dat[1] + 1/3)/(sum(dat) + 1)
  p_k <- (dat[2] + 1/3)/(sum(dat) + 1)
  p <- (dat[1] + 1/3)/(sum(dat) + 1)
  
  # (dat[1] + 1/2)/(sum(dat[1:2]) + 1)
  
  # log(p_r/p_k)
  # log(p/(1 - p))
  # qnorm(p_r)- qnorm(p_k)
  (dat[1] - dat[2])/sum(dat)
  
  # p_r/(p_r + p_k)
}

y <- apply(dat, 2, make_y)

###Design matrices

#Mu
X_u <- matrix(0, nrow = length(y), ncol = 4)
for(i in 1:length(y)){
  X_u[i, cond[i]] <- 1
}

#M0
X_star <- X_u[, 1:3]
X_star[,3] <- X_u[,3] + X_u[,4]

#M_A1
X_A1 <- X_star[, 2:3]
X_A1[,1] <- X_star[,1] + X_star[,2]

#No design matrices for the other two models are needed
#, since they have the same design matrix as M_u

###Estimation & Bayes factors for raw models using bayesfactor package

#Mu
gMap <- rep(0, 4)
samples_u <- nWayAOV(y, X_u, gMap, rscale = 2/3
                     , posterior = T, iterations = 100000)
out_u <- nWayAOV(y, X_u, gMap, rscale = 2/3)

#M0
gMap <- rep(0, 3)
samples_star <- nWayAOV(y, X_star, gMap, rscale = 2/3
                        , posterior = T, iterations = 100000)
out_star <- nWayAOV(y, X_star, gMap, rscale = 2/3)

#MA1
gMap <- rep(0, 2)
# samples_A1 <- nWayAOV(y, X_A1, gMap, rscale = 1, posterior = T)
out_A1 <- nWayAOV(y, X_A1, gMap, rscale = 2/3)

###Bayes factor computation using encompassing approach Haaf&Rouder

#M0
est.star <- samples_star[,1] + samples_star[, 2:4]
colMeans(est.star)

##Posterior prob of mu1> mu2
# star <- est.star[,1] > 0 & est.star[,2] < 0
star <- est.star[,1] > est.star[,2]
post.prob.star <- mean(star)

##Prior prob of mu1 > mu2
R <- 100000
mu.theta.sd <- .5
mu1 <- rnorm(R, 0, mu.theta.sd)
mu2 <- rnorm(R, 0, mu.theta.sd)
# priorstar <- mu1 > 0 & mu2 < 0
priorstar <- mu1 > mu2
prior.prob.star <- mean(priorstar)

#MA2
est.u <- samples_u[,1] + samples_u[, 2:5]
colMeans(est.u)

##Posterior
a2 <- est.u[,1] > est.u[,2] & est.u[,3] > est.u[,4]
post.prob.a2 <- mean(a2)

##Prior prob
mu1 <- rnorm(R, 0, mu.theta.sd)
mu2 <- rnorm(R, 0, mu.theta.sd)
mu3 <- rnorm(R, 0, mu.theta.sd)
mu4 <- rnorm(R, 0, mu.theta.sd)
priora2 <- mu1 > mu2 & mu3 > mu4
prior.prob.a2 <- mean(priora2)

#MA3
##Posterior
a3 <- est.u[,1] < est.u[,2] & est.u[,3] < est.u[,4]
post.prob.a3 <- mean(a3)

##Prior prob
priora3 <- mu1 < mu2 & mu3 < mu4
prior.prob.a3 <- mean(priora3)

#MA4
##Posterior
a4 <- est.u[,1] > est.u[,2] & est.u[,3] < est.u[,4]
post.prob.a4 <- mean(a4)

##Prior prob
priora4 <- mu1 > mu2 & mu3 < mu4
prior.prob.a4 <- mean(priora4)

#bfs everything compared to M0
bf.starbase <- log(post.prob.star / prior.prob.star) + out_star$bf
bf.a2base <- log(post.prob.a2 / prior.prob.a2) + out_u$bf
bf.a3base <- log(post.prob.a3 / prior.prob.a3) + out_u$bf
bf.a4base <- log(post.prob.a4 / prior.prob.a4) + out_u$bf
(bf.staru <- exp(bf.starbase - out_u$bf))
(bf.stara1 <- exp(bf.starbase - out_A1$bf))
(bf.stara2 <- exp(bf.starbase - bf.a2base))
(bf.stara3 <- exp(bf.starbase - bf.a3base))
(bf.stara4 <- exp(bf.starbase - bf.a4base))
```

# Other

## Other (Optional)
<!-- If there is any additional information that you feel needs to be included in your preregistration, please enter it here. -->

### Stimuli

*Words*

'BATH', 'BEEF', 'BIRD', 'BLUE', 'BOOK', 'CAKE', 'CALL', 'COAT', 'COLD', 'DATE', 'DOOR', 'FACE', 'FACT', 'FEET', 'GIRL', 'GOOD', 'HALF', 'HALL', 'HAND', 'HAVE', 'HEAD', 'HELP', 'HOLD', 'HOME', 'KISS', 'KNEE', 'LEFT', 'LIFE', 'LIKE', 'LINE', 'LOOK', 'MAKE', 'MIND', 'NOTE', 'PAGE', 'RAIN', 'REST', 'ROAD', 'ROOM', 'SALT', 'SEAT', 'SELF', 'SHOP', 'SKIN', 'SNOW', 'SOAP', 'SOFT', 'SONG', 'TALK', 'TIME', 'TREE', 'WALK', 'WANT', 'WARM', 'WASH', 'WIND', 'WORK', 'YEAR', 'GATE', 'CASH'

*Non-Words*

'WUIL', 'RILM', 'DENC', 'ZYSE', 'LODD', 'CHIE', 'SEFS', 'JAUK', 'GWIC', 'WONE', 'PLOK', 'DAPT', 'RETE', 'KLIB', 'SIME', 'LATT', 'SWAZ', 'DUFE', 'WONS', 'HEWF', 'MENC', 'ZUNK', 'COLV', 'CLOF', 'ABST', 'YOGG', 'DAUV', 'VEUL', 'HOAB', 'DOYS', 'SPIZ', 'NARN', 'ZELF', 'YAIL', 'CWEB', 'NOGE', 'WONC', 'DWEK', 'ZARC', 'GWUZ', 'NALN', 'HESP', 'JALT', 'UFTS', 'CWUL', 'KEPH', 'MYDE', 'SOTE', 'CHUR', 'FOMB', 'FOSK', 'TRUV', 'SNUZ', 'TASP', 'NAUC', 'VABB', 'ZEAM', 'TUCE', 'JOSP', 'LORT'

### Remember/Know instructions

*Now is the memory test for the words and non-words you studied before. You will see a single item at a time; some of these will be from the set you studied in the first part of the experiment (OLD), others will be ones you did not study (NEW). Please work carefully through each item, indicating for each one whether you recognize it from the first part of the study or not. If you recognize an item, please click the OLD button. If you do not recognize it, plase click the NEW button. Press SPACE to continue*

*Additionally, as you make your decision about recognizing each word/ non-word, bear in mind the following: Often, when remembering a previous event or occurence, we consciously RECOLLECT and become aware of aspects of the previous experience. At other times, we simply KNOW that something has occurred before, but without being able consciously to recollect anything about its occurrence or what we experienced at the time. Press SPACE to continue*

*Thus in addition to your indicating your recognition of a word/ non-word from the original study set, you will be asked to click 'R' to show that you recollect the item consciously, or click 'K' if you feel you simply know that the item was in the previous study set. So, for each item that you recognize as OLD, please click 'R' if you recollect its occurrence, or 'K' if you simply know that it was shown in the first part of the experiment. Press SPACE to begin*

---
nocite: | 
   @Haaf:Rouder:2017, @Rouder:Haaf:2018, @Coltheart:1981, @Gardiner:Java:1990, @Rastle:etal:2002
...



## 
\vspace{-2pc}
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{-1in}
\setlength{\parskip}{8pt}
\noindent

# References
