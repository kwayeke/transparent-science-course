---
title           : "Recollective experience in recognition: A replication of Gardiner and Java (1990)"
shorttitle      : "Replication of Gardiner and Java (1990)"
date            : "`r Sys.setlocale('LC_TIME', 'C'); format(Sys.time(), '%d\\\\. %B %Y')`"

author: 
  - name        : Julia Haaf
    affiliation : 1
  - name        : Stephen Rhodes
    affiliation : 1
  - name        : Jeffrey Rouder
    affiliation : 1, 2

affiliation:
  - id          : 1
    institution : University of Missouri
  - id          : 2
    institution : University of California, Irvine
    
bibliography      : "../lab.bib"
output: prereg::cos_prereg
---

# Study Information

## Title

`r rmarkdown::metadata$title`

## Research questions


In the literature on memory there is disagreement on the processes underlying recognition. Dual process theorists propose that recognition decisions can be done on the basis of recollection, that is, reinstatement of the context in which the item was studied, or familiarity, that is, a sense that the information was previously encountered without the accompanying contextual details. These processes have been mapped onto the phenomenological sensation of 'remembering' a specific event versus 'knowing' that it occurred. In contrast, single process models propose that these sensations reflect the same process, just different levels of memory strength. These single process models have been effective in reproducing effects that have been considered strong evidence for two processes.

Gardiner and Java (1990) report remember/know/new data that heavily favor the dual process account. In their Experiment 2, participants (N=20) studied 15 words and 15 non-words and, following a 24 hour delay, their memory was tested with an old/ new recognition procedure (30 old, 30 new items). Crucially, for items classified as old Gardiner and Java required participants to make an additional classification. Participants were instructed to respond "remember" when they could recall specific contextual details, or respond "know" when they simply felt like they had encountered the item. Their data (their Figure 2) demonstrated a clear cross over interaction, such that words elicited far more "remember" responses, whereas non-words elicited more "know" responses. Importantly, the frequency of "remember" and "know" responses did not differ between unstudied (new) words and non-words.  

The cross over interaction for old items in conjunction with a lack of effect for new items is highly constraining for theories of recognition and strongly favor a dual process model. Given their potential theoretical significance, the present study aims to replicate the findings of Gardiner and Java [-@Gardiner:Java:1990].

## Models

Gardiner and Java (1990) first hypotheses, denoted $H_1$, is that *remember* responses would be more prevalent for old words than old non-words.  Their second hypothesis, $H_2$, is that *know* responses would be more prevalent for old non-words than for old words.  Though not explicitly hypothesized, they found no effect of item type (word vs. non-word), and we call this relationship $H_3$.  These three hypotheses are not exclusive; Gardiner and Java claim all were born out in their data.

Unfortunately, $H_1$ and $H_2$ are not independent.  There is negative correlation because any endorsement of a *remember* response necessarily implies a lack of endorsement of a *know* response. This negative correlation was not accounted for by Gardiner and Java.  The failure to do so strikes us as a substantial error in need or redress.

We find the specification of *models* to be more precise and more informative than the specification of *hypotheses*.  We start with data representation.  Let $r_{ij}$, $k_{ij}$, and $n_{ij}$ denote the number of *remember*, *know* and *new* responses, respectively for the $i$th participant and $j$ stimulus, $i=1,\ldots,I$ and $j=1,\ldots,4$, where the 4 conditions are old words, old non-words, new words, and new non-words, respectively.  To account for the negative correlation, we consider the relative difference between remember and know responses, or $Y_{ij}=(r_{ij} - k_{ij})/(r_{ij}+k_{ij} + n_{ij})$.  

The most general model, what we called the *unconstrained model*, is 
\[
M_u: \quad Y_{ij}\sim\mbox{Normal}(\mu_j,\sigma^2).
\]

The Gardiner \& Java hypotheses can be instantiated with the following restrictions:
\[
M_0: \quad \mu_1 > 0, \; \mu_2 < 0, \; \mu_3=\mu_4.
\]

In addition to the unconstrained model, we propose the following alternatives to competitively test $M_0$ against.  
\[
\begin{aligned}
M_1: \quad &\mu_1 = \mu_2, \; \mu_3=\mu_4.\\
M_2: \quad &\mu_1 > \mu_2, \; \mu_3 > \mu_4.\\
M_3: \quad &\mu_1 < \mu_2, \; \mu_3 < \mu_4.
\end{aligned}
\]

Model $M_1$ captures the case that word/non-word status has no effect on the relative difference; Model $M_2$ captures the case that words whether old or new enhance remember responses over know responses through a criteria effect; Model $M_3$ captures the opposite case that non-words whether old or new enhance remember responses over know responses through a criteria effect.  The unconstrained model captures these relations as well as all others.


# Sampling Plan

Fifty undergraduate students participating for course credit. 

## Existing data

**Registration prior to creation of data**. As of the date of submission of this research plan for preregistration, the data have not yet been collected, created, or realized.

## Data collection procedures

Undergraduate students will be recruited by the University of Missouri SONA system from the PSYCH 1000 course. Participants will be screened for normal or corrected to normal vision and will be fluent speakers of English. participants will be tested in the Perception and Cognition lab or Memory and Cognitive Aging lab at the University of Missouri.

## Sample size
We plan on asking each of 50 participants to judge 60 words and 60 non-words.  The total number of judgments is therefore `r 50*2*60`.  

## Sample size rationale

We think `r 50*2*60` judgments is a lot.  It is 5 times the number of judgments collected by Gardiner and Java in their Experiment 2.

# Variables

Manipulated
 - Stimulus type: word/ non-word
 - Probe type: old/ new

Measured
 - Frequency of New, Old and Remember, Know responses
 - Reaction time


# Design Plan

2 $\times$ 2 within subjects

## Study type

**Experiment**. A researcher randomly assigns treatments to study subjects, this includes field or lab experiments. This is also known as an intervention experiment and includes randomized controlled trials.

## Blinding

This study is a massively repeated within-subjects design.  What does blinding even mean when participants are assigned to both conditions.

## Study design
<!-- Describe your study design. Examples include two-group, factorial, randomized block, and repeated measures. Is it a between (unpaired), within-subject (paired), or mixed design? Describe any counterbalancing required. Typical study designs for observation studies include cohort, cross sectional, and case-control studies. -->

Repeated measures

### Stimuli

Sixty high familiarity concrete nouns with 1 syllable and 4 letters were taken from the MRC psycholinguistics database (Coltheart, 1981). Sixty non-words with 4 letters and 2-4 phonemes were selected from the ARC non-word database (Rastle et al., 2002). For each participant 30 words and 30 non-words are chosen at random to form the study set. Words and non-words are randomly intermixed. All 60 words and 60 non-words are presented at test in a random order. The words and non-words used in this study are copied below at the end of this document. Items are presented at the center of the screen in the Lucida Console font with a height of 2$^{\circ}$ of visual angle at an approximate viewing distance of 50 cm.

During the recognition test participants are presented with a single item in the center of the screen and two buttons (either labeled OLD and NEW or R and K, see below) that they can click on to respond. The buttons are circular with a radius of 2$^{\circ}$ and are presented $5^{\circ}$ below and $5^{\circ}$ to the left and right of the center of the screen.

### Procedure

Participants study 60 items (30 words and 30 non-words) in a randomly determined order. Each item appears on screen for 2 seconds followed by a 0.5 second inter-stimulus-interval. Following the study phase participants are given a 'spot-the-difference' task to complete for 10 minutes before moving on to the recognition test. During the recognition test participants are presented with items one at a time that they must first characterize as OLD or NEW using the mouse to click on labeled buttons on screen. Following an OLD response participants then make an additional characterization by clicking on buttons labeled R (for 'remembered') or K (for 'known'). Prior to the recognition test participants are instructed on the use of the R/K classification in a similar manner to the instruction used in Gardiner and Java (1990). These instructions are copied below in the final section of this document.

## Randomization
<!-- If you are doing a randomized study, how will you randomize, and at what level? -->

Order of presentation of word/ non-words is randomized. Whether a given word/ non-word is old or new is also determined randomly per person.

# Analysis Plan
<!-- You may describe one or more confirmatory analysis in this section. Remember, all analyses specified in this section must be reported in the final article, and any additional analyses must be clearly labeled as exploratory or hypothesis generating in the final paper. A confirmatory analysis plan must state up front which variables are predictors (independent) and which are the outcomes (dependent), otherwise it is an exploratory analysis.

You may describe exploratory analyses in this section, but a clear confirmatory analysis is required. An exploratory test is any test where a prediction is not made up front, or there are multiple possible tests that you are going to use. A statistically significant finding in an exploratory test is a great way to form a new confirmatory hypothesis, which could be registered at a later time.

To help you keep track of multiple analyses, you may label each for your reference. -->

We intend to use the Bayes factor approach to assessing equalities and inequalities as described in Haaf & Rouder (in press) and Rouder & Haaf (submitted). 

The key specifications that are needed are the scale on effect sizes.  We think a guess for $\sigma^2$ is somewhere around .3, and if effects are .2, then effect sizes should be around .67.  This value will be used to set our scales along the arguments of Haaf and Rouder (in press).  

## Statistical models
Defined above.

## Transformations
<!-- If you plan on transforming, centering, recoding the data, or will require a coding scheme for categorical variables, please describe that process. -->

Defined above.

## Follow-up analyses
<!-- If not specified previously, will you be conducting any confirmatory analyses to follow up on effects in your statistical model, such as subgroup analyses, pairwise or complex contrasts, or follow-up tests from interactions. Refer to the *Hypotheses* section to relate each hypothesis to a statistical analysis. Remember that any analyses not specified in this research plan must be noted as exploratory. -->

We will fit an equal variance signal detection model to assess the applicability of a simple one-process model.

## Inference criteria
<!-- What criteria will you use to make inferences? Please describe the information you'll use (e.g. p-values, Bayes factors, specific model fit indices), as well as cut-off criterion, where appropriate. Will you be using one or two tailed tests for each of your analyses? If you are comparing multiple conditions or testing multiple hypotheses, will you account for this? -->

Such considerations only make sense in the Neyman-Fisher statistical framework.  We don't make decisions .  Instead, we state the strength of evidence, and no criteria are needed.  See @Rouder:etal:2016c.

## Data exclusion
<!-- How will you determine what data or samples, if any, to exclude from your analyses? How will outliers be handled? -->

If the session is terminated (either by the participant or for technical reasons) the whole data set will be excluded. We have no set lower bound of performance, but we reserve the right to do exclude low-performing participants on an exploratory basis.  We do so with regards to the overall accuracy and explicitly not the accuracy-by-condition data.

## Missing data
<!-- How will you deal with incomplete or missing data? -->

Any missing will be replaced by recruiting additional participants (up to a total of 50).




## Exploratory analyses (optional)
<!-- If you plan to explore your data set to look for unexpected differences or relationships, you may describe those tests here. An exploratory test is any test where a prediction is not made up front, or there are multiple possible tests that you are going to use. A statistically significant finding in an exploratory test is a great way to form a new confirmatory hypothesis, which could be registered at a later time. -->

We do not have a set analysis script for the exploratory EVSD analysis. The script will look something like the one below. The data used here is from the graph for experiment 2 from Gardiner and Java [-@Gardiner:Java:1990].

```{r eval = F}
dat2=matrix(ncol=2,byrow=T,c(
.28,.16,
.19,.30,
.03,.12,
.04,.11))

new=1-apply(dat2,1,sum)
dat=cbind(dat2,new)
colnames(dat)=c("Rem","Know","New")
rownames(dat)=c("oldW","oldNW","newW","newNW")


pred=function(par)
{
oldW=diff(pnorm(c(-Inf,par[3:4],Inf),par[1],1))
oldNW=diff(pnorm(c(-Inf,par[5:6],Inf),par[2],1))
newW=diff(pnorm(c(-Inf,par[3:4],Inf),0,1))
newNW=diff(pnorm(c(-Inf,par[5:6],Inf),0,1))
p=rbind(oldW,oldNW,newW,newNW)
p=p[,3:1]
colnames(p)=c("Rem","Know","New")
rownames(p)=c("oldW","oldNW","newW","newNW")
return(p)
}

error=function(par,dat){
	p=pred(par) 
	return(sum ((qnorm(p)-qnorm(dat))^2))
	}

par=c(1,1,1,1.5,1,1.5)

error(par,dat)
g=optim(par,error,dat=dat)
h=nlm(error,g$par,dat=dat)
g=optim(h$estimate,error,dat=dat)

print(pred(g$par))
```



## Analysis scripts (optional)
<!-- The purpose of a fully commented analysis script is to unambiguously provide the responses to all of the questions raised in the analysis section. This step is not common, but we encourage you to try creating an analysis script, refine it using a modeled dataset, and use it in place of your written analysis plan.

Upload an analysis script with clear comments. This optional step is helpful in order to create a process that is completely transparent and increase the likelihood that your analysis can be replicated. We recommend that you run the code on a simulated dataset in order to check that it will run without errors. -->

Let `dat` be a $3\times IJ$ matrix of response frequencies for remember, know and new responses per condition and person. Let `cond` be a vector of length $IJ$ denoting the condition $j$ for each column in `dat`. Likewise, let `sub` be a vector of length $IJ$ denoting the participant $i$ for each column in `dat`.

```{r, eval = F}
library("knitr")
library('BayesFactor')

make_y <- function(dat){ 
  #vector of 3 values
  #, first = number of remember responses
  #, second = number of know responses
  #, third = number of new responses
  if(!is.vector(dat)){return("data not in the right format")}
  if(length(dat)!=3){
    return("please submit vector with #remember
           , #know and #new responses")}
  
  p_r <- (dat[1] + 1/3)/(sum(dat) + 1)
  p_k <- (dat[2] + 1/3)/(sum(dat) + 1)
  p <- (dat[1] + 1/3)/(sum(dat) + 1)
  
  # (dat[1] + 1/2)/(sum(dat[1:2]) + 1)
  
  # log(p_r/p_k)
  # log(p/(1 - p))
  # qnorm(p_r)- qnorm(p_k)
  (dat[1] - dat[2])/sum(dat)
  
  # p_r/(p_r + p_k)
}

y <- apply(dat, 2, make_y)

###Design matrices

#Mu
X_u <- matrix(0, nrow = length(y), ncol = 4)
for(i in 1:length(y)){
  X_u[i, cond[i]] <- 1
}

#M0
X_star <- X_u[, 1:3]
X_star[,3] <- X_u[,3] + X_u[,4]

#M_A1
X_A1 <- X_star[, 2:3]
X_A1[,1] <- X_star[,1] + X_star[,2]

#No design matrices for the other two models are needed
#, since they have the same design matrix as M_u

###Estimation & Bayes factors for raw models using bayesfactor package

#Mu
gMap <- rep(0, 4)
samples_u <- nWayAOV(y, X_u, gMap, rscale = 2/3
                     , posterior = T, iterations = 100000)
out_u <- nWayAOV(y, X_u, gMap, rscale = 2/3)

#M0
gMap <- rep(0, 3)
samples_star <- nWayAOV(y, X_star, gMap, rscale = 2/3
                        , posterior = T, iterations = 100000)
out_star <- nWayAOV(y, X_star, gMap, rscale = 2/3)

#MA1
gMap <- rep(0, 2)
# samples_A1 <- nWayAOV(y, X_A1, gMap, rscale = 1, posterior = T)
out_A1 <- nWayAOV(y, X_A1, gMap, rscale = 2/3)

###Bayes factor computation using encompassing approach Haaf&Rouder

#M0
est.star <- samples_star[,1] + samples_star[, 2:4]
colMeans(est.star)

##Posterior prob of mu1> mu2
# star <- est.star[,1] > 0 & est.star[,2] < 0
star <- est.star[,1] > est.star[,2]
post.prob.star <- mean(star)

##Prior prob of mu1 > mu2
R <- 100000
mu.theta.sd <- .5
mu1 <- rnorm(R, 0, mu.theta.sd)
mu2 <- rnorm(R, 0, mu.theta.sd)
# priorstar <- mu1 > 0 & mu2 < 0
priorstar <- mu1 > mu2
prior.prob.star <- mean(priorstar)

#MA2
est.u <- samples_u[,1] + samples_u[, 2:5]
colMeans(est.u)

##Posterior
a2 <- est.u[,1] > est.u[,2] & est.u[,3] > est.u[,4]
post.prob.a2 <- mean(a2)

##Prior prob
mu1 <- rnorm(R, 0, mu.theta.sd)
mu2 <- rnorm(R, 0, mu.theta.sd)
mu3 <- rnorm(R, 0, mu.theta.sd)
mu4 <- rnorm(R, 0, mu.theta.sd)
priora2 <- mu1 > mu2 & mu3 > mu4
prior.prob.a2 <- mean(priora2)

#MA3
##Posterior
a3 <- est.u[,1] < est.u[,2] & est.u[,3] < est.u[,4]
post.prob.a3 <- mean(a3)

##Prior prob
priora3 <- mu1 < mu2 & mu3 < mu4
prior.prob.a3 <- mean(priora3)

#MA4
##Posterior
a4 <- est.u[,1] > est.u[,2] & est.u[,3] < est.u[,4]
post.prob.a4 <- mean(a4)

##Prior prob
priora4 <- mu1 > mu2 & mu3 < mu4
prior.prob.a4 <- mean(priora4)

#bfs everything compared to M0
bf.starbase <- log(post.prob.star / prior.prob.star) + out_star$bf
bf.a2base <- log(post.prob.a2 / prior.prob.a2) + out_u$bf
bf.a3base <- log(post.prob.a3 / prior.prob.a3) + out_u$bf
bf.a4base <- log(post.prob.a4 / prior.prob.a4) + out_u$bf
(bf.staru <- exp(bf.starbase - out_u$bf))
(bf.stara1 <- exp(bf.starbase - out_A1$bf))
(bf.stara2 <- exp(bf.starbase - bf.a2base))
(bf.stara3 <- exp(bf.starbase - bf.a3base))
(bf.stara4 <- exp(bf.starbase - bf.a4base))
```

# Other

## Other (Optional)
<!-- If there is any additional information that you feel needs to be included in your preregistration, please enter it here. -->

### Stimuli

*Words*

'BATH', 'BEEF', 'BIRD', 'BLUE', 'BOOK', 'CAKE', 'CALL', 'COAT', 'COLD', 'DATE', 'DOOR', 'FACE', 'FACT', 'FEET', 'GIRL', 'GOOD', 'HALF', 'HALL', 'HAND', 'HAVE', 'HEAD', 'HELP', 'HOLD', 'HOME', 'KISS', 'KNEE', 'LEFT', 'LIFE', 'LIKE', 'LINE', 'LOOK', 'MAKE', 'MIND', 'NOTE', 'PAGE', 'RAIN', 'REST', 'ROAD', 'ROOM', 'SALT', 'SEAT', 'SELF', 'SHOP', 'SKIN', 'SNOW', 'SOAP', 'SOFT', 'SONG', 'TALK', 'TIME', 'TREE', 'WALK', 'WANT', 'WARM', 'WASH', 'WIND', 'WORK', 'YEAR', 'GATE', 'CASH'

*Non-Words*

'WUIL', 'RILM', 'DENC', 'ZYSE', 'LODD', 'CHIE', 'SEFS', 'JAUK', 'GWIC', 'WONE', 'PLOK', 'DAPT', 'RETE', 'KLIB', 'SIME', 'LATT', 'SWAZ', 'DUFE', 'WONS', 'HEWF', 'MENC', 'ZUNK', 'COLV', 'CLOF', 'ABST', 'YOGG', 'DAUV', 'VEUL', 'HOAB', 'DOYS', 'SPIZ', 'NARN', 'ZELF', 'YAIL', 'CWEB', 'NOGE', 'WONC', 'DWEK', 'ZARC', 'GWUZ', 'NALN', 'HESP', 'JALT', 'UFTS', 'CWUL', 'KEPH', 'MYDE', 'SOTE', 'CHUR', 'FOMB', 'FOSK', 'TRUV', 'SNUZ', 'TASP', 'NAUC', 'VABB', 'ZEAM', 'TUCE', 'JOSP', 'LORT'

### Remember/Know instructions

*Now is the memory test for the words and non-words you studied before. You will see a single item at a time; some of these will be from the set you studied in the first part of the experiment (OLD), others will be ones you did not study (NEW). Please work carefully through each item, indicating for each one whether you recognize it from the first part of the study or not. If you recognize an item, please click the OLD button. If you do not recognize it, plase click the NEW button. Press SPACE to continue*

*Additionally, as you make your decision about recognizing each word/ non-word, bear in mind the following: Often, when remembering a previous event or occurence, we consciously RECOLLECT and become aware of aspects of the previous experience. At other times, we simply KNOW that something has occurred before, but without being able consciously to recollect anything about its occurrence or what we experienced at the time. Press SPACE to continue*

*Thus in addition to your indicating your recognition of a word/ non-word from the original study set, you will be asked to click 'R' to show that you recollect the item consciously, or click 'K' if you feel you simply know that the item was in the previous study set. So, for each item that you recognize as OLD, please click 'R' if you recollect its occurrence, or 'K' if you simply know that it was shown in the first part of the experiment. Press SPACE to begin*

---
nocite: | 
   @Haaf:Rouder:2017, @Rouder:Haaf:2018, @Coltheart:1981, @Gardiner:Java:1990, @Rastle:etal:2002
...



## 
\vspace{-2pc}
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{-1in}
\setlength{\parskip}{8pt}
\noindent

# References
